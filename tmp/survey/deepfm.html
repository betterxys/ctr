<!DOCTYPE HTML>
<html>
 <head>
  <meta charset="utf-8"/>
  <title>
   Made with Remarkable!
  </title>
  <link href="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/styles/github.min.css" rel="stylesheet"/>
  <style type="text/css">
   body,table tr{background-color:#fff}table tr td,table tr th{border:1px solid #ccc;text-align:left;padding:6px 13px;margin:0}pre code,table,table tr{padding:0}hr,pre code{background:0 0}body{font:16px Helvetica,Arial,sans-serif;line-height:1.4;color:#333;word-wrap:break-word;padding:10px 15px}strong,table tr th{font-weight:700}h1{font-size:2em;margin:.67em 0;text-align:center}h2{font-size:1.75em}h3{font-size:1.5em}h4{font-size:1.25em}h1,h2,h3,h4,h5,h6{font-weight:700;position:relative;margin-top:15px;margin-bottom:15px;line-height:1.1}h1,h2{border-bottom:1px solid #eee}hr{height:0;margin:15px 0;overflow:hidden;border:0;border-bottom:1px solid #ddd}a{color:#4183C4}a.absent{color:#c00}ol,ul{padding-left:15px;margin-left:5px}ol{list-style-type:lower-roman}table tr{border-top:1px solid #ccc;margin:0}table tr:nth-child(2n){background-color:#aaa}table tr td :first-child,table tr th :first-child{margin-top:0}table tr td:last-child,table tr th :last-child{margin-bottom:0}img{max-width:100%}blockquote{padding:0 15px;border-left:4px solid #ccc}code,tt{margin:0 2px;padding:0 5px;white-space:nowrap;border:1px solid #eaeaea;background-color:#f8f8f8;border-radius:3px}pre code{margin:0;white-space:pre;border:none}.highlight pre,pre{background-color:#f8f8f8;border:1px solid #ccc;font-size:13px;line-height:19px;overflow:auto;padding:6px 10px;border-radius:3px}
  </style>
 </head>
 <body>
  <h1 id="ctr-deepfm">
   CTR - DeepFM
  </h1>
  <div class="toc">
   <ul>
    <li>
     <a href="#ctr-deepfm">
      CTR - DeepFM
     </a>
     <ul>
      <li>
       <a href="#_1">
        简介
       </a>
      </li>
      <li>
       <a href="#_2">
        优势
       </a>
      </li>
      <li>
       <a href="#_3">
        检验数据集
       </a>
      </li>
      <li>
       <a href="#_4">
        超参设置
       </a>
      </li>
      <li>
       <a href="#deepfm">
        DeepFM的结构
       </a>
       <ul>
        <li>
         <a href="#_5">
          公式变量说明
         </a>
        </li>
        <li>
         <a href="#input-and-embedding-layer">
          input and embedding layer
         </a>
        </li>
        <li>
         <a href="#fm-component">
          FM Component
         </a>
        </li>
        <li>
         <a href="#deep-component">
          Deep Component
         </a>
        </li>
        <li>
         <a href="#output-layer">
          Output layer
         </a>
        </li>
       </ul>
      </li>
     </ul>
    </li>
   </ul>
  </div>
  <h3 id="_1">
   简介
  </h3>
  <p>
   主要分为deep和wide两部分，deep模块使用deep learning学习高阶feature interaction，wide模块使用FM提取低阶feature interaction，deep和wide两个模块共享输入和embeddings，最终通过output layer进行结合，输出CTR，在训练时，deep和wide组成一个整体model，同时参与训练；
  </p>
  <h3 id="_2">
   优势
  </h3>
  <ol>
   <li>
    end to end, 不需要任何预先的特征工程
   </li>
   <li>
    结合了FM和DNN，可以同时充分的提取低阶(FM)和高阶(DNN)feature interactions
   </li>
   <li>
    在bench-mark数据集和商用数据集上与state of the art的模型同时做了对比实验，实现全方位碾压
   </li>
  </ol>
  <h3 id="_3">
   检验数据集
  </h3>
  <p>
   bench-mark data: crito dataset, 包含4500w用户的点击行为记录，13个连续型特征，26个离散型特征；以9：1的比例进行训练和测试；测试集结果：AUC=0.8007, LogLoss=0.45083.
   <br/>
   commercial data:  某公司app store当中game center的连续8天的点击行为记录，共计10亿条记录，其中7天作为训练，1天作为测试；测试集结果：AUC=0.8715, Logloss=0.02618.
  </p>
  <h3 id="_4">
   超参设置
  </h3>
  <p>
   与FNN和PNN的paper参数一致：
  </p>
  <ul>
   <li>
    dropout: 0.5
   </li>
   <li>
    nerwork-structure: 400-400-400
   </li>
   <li>
    optimizer: Adam
   </li>
   <li>
    activation function: Relu
   </li>
   <li>
    latent dimension: 10
   </li>
  </ul>
  <h3 id="deepfm">
   DeepFM的结构
  </h3>
  <p>
   <img alt="architecture of DeepFM" src="../figs/deepfm.png" title="DeepFM"/>
  </p>
  <h4 id="_5">
   公式变量说明
  </h4>
  <p>
   假设训练集有n个样本，m个特征，则一个输入样本可以表示为：
  </p>
  <p>
   <mathjax>
    $$x = [x_{field_1}, x_{field_2}, x_{field_3}, ..., x_{field_m}]$$
   </mathjax>
  </p>
  <p>
   每个field代表一个特征，其中离散特征用one hot encoding向量表示，连续特征用其连续值或者其分布情况的one hot encoding向量表示，所以假设输入x是一个d维向量
  </p>
  <h4 id="input-and-embedding-layer">
   input and embedding layer
  </h4>
  <ul>
   <li>
    <p>
     input layer的输入特征一般都较为稀疏、高维；
    </p>
   </li>
   <li>
    <p>
     embedding layer在DNN当中的主要作用是降维，同时可以更有效的帮助FM提取二阶interactions, embedding layer结构具备如下特点：
    </p>
    <ul>
     <li>
      <p>
       不论输入特征的大小是多少，其embeddings大小都是固定的k
      </p>
     </li>
     <li>
      <p>
       FM和DNN共享latent vector，FM当中二阶feature interactions是根据latent vector的内积计算的，在DNN当中latent vector是从input vector变换到embedding vector所需的参数；
      </p>
     </li>
     <li>
      <p>
       用\(e_i\)表示第i个特征对应的embedding,则embedding layer的输出是：
      </p>
     </li>
    </ul>
   </li>
  </ul>
  <p>
   <mathjax>
    $$ a^{(0)} = [e_1, e_2, e_3, ... , e_m] $$
   </mathjax>
  </p>
  <h4 id="fm-component">
   FM Component
  </h4>
  <p>
   FM主要包括三层：input layer, embedding layer和fm layer，最终将结果输出到output layer；FM的主要目标是获取一阶和二阶feature interactions:
  </p>
  <ul>
   <li>
    <p>
     order-1 interaction
     <br/>
     各个输入特征加权求和以生成一阶interaction;
    </p>
   </li>
   <li>
    <p>
     order-2 interaction
     <br/>
     实质上每个输入特征值对应一个one hot encoding向量，那么每个特征值同样对应有一个feature latent vector:\( V_i \)，通过latent vector之间的内积可以更有效的提取二阶feature interactions.
    </p>
   </li>
  </ul>
  <p>
   FM component可以表示为一个加法单元和一个内积单元：
  </p>
  <p>
   <mathjax>
    $$
y_{FM} = &lt;w,x&gt; + 
\sum_{j_1 = 1}^{d} \sum_{j_2 = j_1 + 1}^{d} &lt;V_i, V_j&gt; x_{j_1} x_{j_2}
= &lt;w,x&gt; + 
\sum_{j_1 = 1}^{d} \sum_{j_2 = j_1 + 1}^{d} &lt;e_{j_1}, e_{j_2}&gt;
$$
   </mathjax>
  </p>
  <h4 id="deep-component">
   Deep Component
  </h4>
  <p>
   DNN主要包括三层：input layer, embedding layer和hidden layer，hidden layer的结果输出到output layer; Deep Component的主要目的是学习高阶feature interactions.
  </p>
  <p>
   input layer的input vector经过embedding layer变成了\(a^{(0)}\)，然后输入到DNN当中，若令\(l\)表示神经网络层的深度，则有：
  </p>
  <p>
   <mathjax>
    $$ a^{(l+1)} = \sigma(W^{(l)} a^{(l)} + b^{(l)}) $$
   </mathjax>
  </p>
  <p>
   若DNN的深度为H，则DNN的输出结果表示为：
  </p>
  <p>
   <mathjax>
    $$ y_{DNN} = \sigma(W^{|H|+1} a^H + b^{|H|+1}) $$
   </mathjax>
  </p>
  <h4 id="output-layer">
   Output layer
  </h4>
  <p>
   output layer简单的将FM和DNN模块的输出结果求和，再通过一个sigmoid函数转换为CTR：
  </p>
  <p>
   <mathjax>
    $$ \hat{y} = sigmoid(y_{FM} +y_{DNN}) $$
   </mathjax>
  </p>
  <script src="http://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.1/highlight.min.js">
  </script>
  <script>
   hljs.initHighlightingOnLoad();
  </script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript">
  </script>
  <script type="text/javascript">
   MathJax.Hub.Config({"showProcessingMessages" : false,"messageStyle" : "none","tex2jax": { inlineMath: [ [ "$", "$" ] ] }});
  </script>
 </body>
</html>